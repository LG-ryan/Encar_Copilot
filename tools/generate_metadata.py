"""
ë©”íƒ€ë°ì´í„° ìë™ ìƒì„± ë„êµ¬
MD íŒŒì¼ì˜ H2/H3/H4 êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ë¶„í™”ëœ ë©”íƒ€ë°ì´í„° ìƒì„±
"""
import re
import json
from pathlib import Path
from typing import List, Dict

# ì¹´í…Œê³ ë¦¬ë³„ ë‹´ë‹¹ì ì •ë³´
CONTACT_INFO = {
    "ê·¼íƒœ ë° íœ´ê°€": {
        "team": "P&CíŒ€",
        "name": "ì´ì˜í¬",
        "phone": "010-xxxx-xxxx",
        "email": "lee@encar.com"
    },
    "ì—…ë¬´ í™˜ê²½ ì„¸íŒ…": {
        "team": "ITíŒ€",
        "name": "ê¹€ì² ìˆ˜",
        "phone": "010-yyyy-yyyy",
        "email": "kim@encar.com"
    },
    "ì‚¬ë¬´ì‹¤ ì´ìš©": {
        "team": "ì´ë¬´íŒ€",
        "name": "ë°•ë¯¼ìˆ˜",
        "phone": "010-zzzz-zzzz",
        "email": "park@encar.com"
    },
    "ë³µë¦¬í›„ìƒ": {
        "team": "P&CíŒ€",
        "name": "ì´ì˜í¬",
        "phone": "010-xxxx-xxxx",
        "email": "lee@encar.com"
    },
    "ì—”ì¹´ ì†Œê°œ": {
        "team": "P&CíŒ€",
        "name": "ì´ì˜í¬",
        "phone": "010-xxxx-xxxx",
        "email": "lee@encar.com"
    }
}

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (H2 â†’ ë””ìŠ¤í”Œë ˆì´ ì´ë¦„)
CATEGORY_MAPPING = {
    "ê·¼íƒœ ë° íœ´ê°€": "HR",
    "ì—…ë¬´ í™˜ê²½ ì„¸íŒ…": "IT",
    "ì‚¬ë¬´ì‹¤ ì´ìš©": "ì´ë¬´",
    "ë³µë¦¬í›„ìƒ": "ë³µë¦¬í›„ìƒ",
    "ì—”ì¹´ ì†Œê°œ": "ê¸°ì—… ì†Œê°œ",
    "ì—”ì¹´ë‹·ì»´ ì†Œê°œ": "ë¹„ì¦ˆë‹ˆìŠ¤"
}


def parse_markdown_structure(file_path: Path) -> List[Dict]:
    """MD íŒŒì¼ì˜ ê³„ì¸µ êµ¬ì¡° íŒŒì‹±"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    sections = []
    current_h2 = None
    current_h3 = None
    current_h4 = None
    section_content = []
    section_start_line = 0
    
    for line_num, line in enumerate(lines, 1):
        # H2 ê°ì§€
        if line.startswith('## '):
            # ì´ì „ ì„¹ì…˜ ì €ì¥
            if current_h2:
                sections.append({
                    "h2": current_h2,
                    "h3": current_h3,
                    "h4": current_h4,
                    "content": ''.join(section_content),
                    "start_line": section_start_line,
                    "end_line": line_num - 1
                })
            
            current_h2 = line.replace('## ', '').strip()
            current_h3 = None
            current_h4 = None
            section_content = []
            section_start_line = line_num
        
        # H3 ê°ì§€
        elif line.startswith('### '):
            # ì´ì „ H3 ì„¹ì…˜ ì €ì¥
            if current_h3 or current_h4:
                sections.append({
                    "h2": current_h2,
                    "h3": current_h3,
                    "h4": current_h4,
                    "content": ''.join(section_content),
                    "start_line": section_start_line,
                    "end_line": line_num - 1
                })
            
            current_h3 = line.replace('### ', '').strip()
            current_h4 = None
            section_content = []
            section_start_line = line_num
        
        # H4 ê°ì§€
        elif line.startswith('#### '):
            # ì´ì „ H4 ì„¹ì…˜ ì €ì¥
            if current_h4:
                sections.append({
                    "h2": current_h2,
                    "h3": current_h3,
                    "h4": current_h4,
                    "content": ''.join(section_content),
                    "start_line": section_start_line,
                    "end_line": line_num - 1
                })
            
            current_h4 = line.replace('#### ', '').strip()
            section_content = []
            section_start_line = line_num
        
        else:
            section_content.append(line)
    
    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_h2:
        sections.append({
            "h2": current_h2,
            "h3": current_h3,
            "h4": current_h4,
            "content": ''.join(section_content),
            "start_line": section_start_line,
            "end_line": len(lines)
        })
    
    return sections


def extract_keywords(text: str, title: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keywords = []
    
    # ì œëª©ì—ì„œ í‚¤ì›Œë“œ
    if title:
        keywords.extend(title.split())
    
    # ë³¸ë¬¸ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ (ê°„ë‹¨í•œ ë°©ì‹)
    words = re.findall(r'[ê°€-í£a-zA-Z0-9]+', text)
    word_freq = {}
    for word in words:
        if len(word) >= 2:
            word_freq[word] = word_freq.get(word, 0) + 1
    
    # ë¹ˆë„ ìƒìœ„ 5ê°œ ì¶”ê°€
    top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
    keywords.extend([word for word, _ in top_words])
    
    # ì¤‘ë³µ ì œê±°
    return list(set(keywords))[:10]


def generate_metadata() -> Dict:
    """ì „ì²´ ë©”íƒ€ë°ì´í„° ìƒì„±"""
    metadata = {"categories": {}}
    
    # ì—”ì¹´ìƒí™œê°€ì´ë“œ.md ì²˜ë¦¬
    guide_path = Path("docs/ì—”ì¹´ìƒí™œê°€ì´ë“œ.md")
    if guide_path.exists():
        print(f"ğŸ“„ {guide_path} ë¶„ì„ ì¤‘...")
        sections = parse_markdown_structure(guide_path)
        
        for idx, section in enumerate(sections):
            h2 = section.get("h2", "")
            h3 = section.get("h3", "")
            h4 = section.get("h4", "")
            content = section.get("content", "")
            
            # ì„¹ì…˜ ì œëª© ê²°ì • (H4 > H3 > H2 ìš°ì„ ìˆœìœ„)
            title = h4 or h3 or h2
            if not title:
                continue
            
            # ì¹´í…Œê³ ë¦¬ ê²°ì •
            category_display = CATEGORY_MAPPING.get(h2, "ì¼ë°˜")
            
            # ê³ ìœ  ID ìƒì„±
            section_id = f"{category_display}_{idx}"
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = extract_keywords(content, title)
            
            # ë‹´ë‹¹ì ì •ë³´ (ëª¨ë‘ P&CíŒ€ Ryanìœ¼ë¡œ í†µì¼)
            contact = {
                "team": "P&CíŒ€",
                "name": "Ryan",
                "phone": "ì—°ë½ì²˜ ë¯¸ë“±ë¡",
                "email": "ryan@encar.com"
            }
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            metadata["categories"][section_id] = {
                "display_name": category_display,
                "filename": "ì—”ì¹´ìƒí™œê°€ì´ë“œ.md",
                "h2_section": h2,
                "h3_section": h3,
                "h4_section": h4,
                "title": title,
                "start_line": section.get("start_line"),
                "end_line": section.get("end_line"),
                "keywords": keywords,
                "contact": contact
            }
        
        print(f"âœ… {len(sections)}ê°œ ì„¹ì…˜ ì¶”ì¶œë¨")
    
    # ë¹„ì¦ˆë‹ˆìŠ¤.md ì²˜ë¦¬
    business_path = Path("docs/ë¹„ì¦ˆë‹ˆìŠ¤.md")
    if business_path.exists():
        print(f"ğŸ“„ {business_path} ë¶„ì„ ì¤‘...")
        sections = parse_markdown_structure(business_path)
        
        for idx, section in enumerate(sections):
            h2 = section.get("h2", "")
            h3 = section.get("h3", "")
            h4 = section.get("h4", "")
            content = section.get("content", "")
            
            title = h4 or h3 or h2
            if not title:
                continue
            
            section_id = f"ë¹„ì¦ˆë‹ˆìŠ¤_{idx}"
            keywords = extract_keywords(content, title)
            
            metadata["categories"][section_id] = {
                "display_name": "ë¹„ì¦ˆë‹ˆìŠ¤",
                "filename": "ë¹„ì¦ˆë‹ˆìŠ¤.md",
                "h2_section": h2,
                "h3_section": h3,
                "h4_section": h4,
                "title": title,
                "start_line": section.get("start_line"),
                "end_line": section.get("end_line"),
                "keywords": keywords,
                "contact": {
                    "team": "P&CíŒ€",
                    "name": "Ryan",
                    "phone": "ì—°ë½ì²˜ ë¯¸ë“±ë¡",
                    "email": "ryan@encar.com"
                }
            }
        
        print(f"âœ… {len(sections)}ê°œ ì„¹ì…˜ ì¶”ì¶œë¨")
    
    return metadata


if __name__ == "__main__":
    print("="*80)
    print("ğŸ”§ ë©”íƒ€ë°ì´í„° ìë™ ìƒì„± ì‹œì‘")
    print("="*80)
    
    # ë©”íƒ€ë°ì´í„° ìƒì„±
    metadata = generate_metadata()
    
    # ì €ì¥
    output_path = Path("data/documents_metadata.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ğŸ“Š ì´ {len(metadata['categories'])}ê°œ ì„¹ì…˜ ìƒì„±ë¨")
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    category_stats = {}
    for cat_id, cat_data in metadata["categories"].items():
        display_name = cat_data["display_name"]
        category_stats[display_name] = category_stats.get(display_name, 0) + 1
    
    print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ì„¹ì…˜ ìˆ˜:")
    for cat, count in category_stats.items():
        print(f"  - {cat}: {count}ê°œ")
    
    print("\n" + "="*80)


